{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report要求\n",
    "1.preprocess data??\n",
    "2.choose feature: 单词的出现次数排名\n",
    "3.train:SCV??可以再找一找分数更高的训练方式\n",
    "4.evaluate and table: 10-fold 十字交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=False)\n",
      "Train data score:0.844320987654321\n",
      "Fold completed.\n",
      "Test data score:0.7688888888888888\n",
      "Train data score:0.8485185185185186\n",
      "Fold completed.\n",
      "Test data score:0.75\n",
      "Train data score:0.845679012345679\n",
      "Fold completed.\n",
      "Test data score:0.7477777777777778\n",
      "Train data score:0.8451851851851852\n",
      "Fold completed.\n",
      "Test data score:0.7566666666666667\n",
      "Train data score:0.8462962962962963\n",
      "Fold completed.\n",
      "Test data score:0.7588888888888888\n",
      "Train data score:0.845925925925926\n",
      "Fold completed.\n",
      "Test data score:0.7733333333333333\n",
      "Train data score:0.8492592592592593\n",
      "Fold completed.\n",
      "Test data score:0.7588888888888888\n",
      "Train data score:0.847037037037037\n",
      "Fold completed.\n",
      "Test data score:0.7366666666666667\n",
      "Train data score:0.8461728395061728\n",
      "Fold completed.\n",
      "Test data score:0.7411111111111112\n",
      "Train data score:0.8477777777777777\n",
      "Fold completed.\n",
      "Test data score:0.7666666666666667\n",
      "\n",
      "Average Accuracy: 0.767\n",
      "    precision    recall        f1  accuracy\n",
      "1    0.759032  0.760441  0.759699  0.768889\n",
      "2    0.746116  0.750333  0.747062  0.750000\n",
      "3    0.736743  0.735590  0.736142  0.747778\n",
      "4    0.752314  0.756914  0.753437  0.756667\n",
      "5    0.753298  0.758570  0.754744  0.758889\n",
      "6    0.769067  0.768011  0.768503  0.773333\n",
      "7    0.756119  0.751786  0.753339  0.758889\n",
      "8    0.734555  0.728520  0.730232  0.736667\n",
      "9    0.731099  0.734003  0.732331  0.741111\n",
      "10   0.761527  0.762203  0.761850  0.766667\n"
     ]
    }
   ],
   "source": [
    "###现在有两个问题：\n",
    "###1.不知道用什么SVM的模型更好\n",
    "###2.Preprocess data只有split代码\n",
    "###3.可以想办法提高score\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import operator\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "dataset_full=[]\n",
    "url=\"datasets_coursework1/Hateval/hateval.tsv\"\n",
    "\n",
    "\n",
    "def split_data(url):\n",
    "    #File=open(url, \"r\")\n",
    "    #strFile=File.read()\n",
    "    #File.close()\n",
    "    #dataset_line=open(url).readlines()\n",
    "    dataset_line = pd.read_csv(url, sep='\\t')\n",
    "    \n",
    "    #print(dataset_line[:5])\n",
    "    ### ~~~~~~split data each line~~~~~~~~ ###\n",
    "    for index in range(len(dataset_line)):\n",
    "        dataset_full.append((dataset_line['text'][index],dataset_line['label'][index]))\n",
    "    #data_frame=pd.DataFrame(dataset_full)\n",
    "    #print(data_frame.head())   \n",
    "    \n",
    "split_data(url)\n",
    "#print(dataset_full)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\".\")\n",
    "stopwords.add(\",\")\n",
    "stopwords.add(\"!\")\n",
    "stopwords.add(\":\")\n",
    "stopwords.add(\"?\")\n",
    "\n",
    "# Function to get the list of tokens from a string\n",
    "def get_list_tokens(string): \n",
    "    sentence_split=nltk.tokenize.sent_tokenize(string)\n",
    "    list_tokens=[]\n",
    "    for sentence in sentence_split:\n",
    "        list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
    "        for token in list_tokens_sentence:\n",
    "            list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "    return list_tokens\n",
    "\n",
    "# Function to get feature vectors\n",
    "def get_vector_text(list_vocab,string):\n",
    "    vector_text=np.zeros(len(list_vocab))\n",
    "    list_tokens_string=get_list_tokens(string) ##Use function \n",
    "    for i, word in enumerate(list_vocab):\n",
    "        if word in list_tokens_string:\n",
    "        #print (list_tokens_string.count(word))\n",
    "            vector_text[i]=list_tokens_string.count(word) #Count words\n",
    "    return vector_text\n",
    "\n",
    "\n",
    "# Function to retrieve features based on bag of words\n",
    "def get_vocabulary(training_set, num_features): \n",
    "    vocabulary_inner=[]\n",
    "    dict_word_frequency={}\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])##Use function\n",
    "        for word in sentence_tokens:\n",
    "            if word in stopwords: continue\n",
    "            if word not in dict_word_frequency: dict_word_frequency[word]=1\n",
    "            else: dict_word_frequency[word]+=1\n",
    "    sorted_list = sorted(dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True)[:num_features]  \n",
    "    for word,frequency in sorted_list:\n",
    "        vocabulary_inner.append(word)\n",
    "    return vocabulary_inner\n",
    "\n",
    "# Function for training our svm classifier\n",
    "def train_svm_classifier(training_set, vocabulary): \n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    for instance in training_set:\n",
    "        vector_instance=get_vector_text(vocabulary,instance[0]) \n",
    "        X_train.append(vector_instance)\n",
    "        Y_train.append(instance[1])\n",
    "    #test_svm_function(X_train,Y_train) # Parameters Adjustment \n",
    "    scaler = StandardScaler() \n",
    "    #print(scaler)\n",
    "    X_scaled = scaler.fit_transform(X_train) #StandScaler Training dataset\n",
    "    #print(X_scaled)\n",
    "    #test_svm_function(X_train,Y_train)\n",
    "    #svm_clf=sklearn.svm.SVC(kernel=\"rbf\",gamma=3.59) #train:99.7%, test:55.8%\n",
    "    svm_clf=sklearn.svm.SVC(kernel=\"linear\",C=1,gamma='auto') #train:85% test:76%\n",
    "    #svm_clf=sklearn.svm.SVC(kernel=\"poly\",degree=2,gamma='auto')#train:59% test 58%\n",
    "    svm_clf.fit(X_scaled,Y_train)\n",
    "    print(\"Train data score:\"+str(svm_clf.score(X_scaled,Y_train)))\n",
    "    \n",
    "    return svm_clf\n",
    "\n",
    "#learning curve\n",
    "def test_svm_function(X_train,Y_train):\n",
    "    gamma_range=np.logspace(0,1,10)\n",
    "    score=[]\n",
    "    for i in gamma_range:\n",
    "        svm_clf=SVC(kernel=\"rbf\",gamma=i,cache_size=5000).fit(X_train,Y_train)\n",
    "        score.append(svm_clf.score(X_train,Y_train))\n",
    "    print(max(score),gamma_range[score.index(max(score))])\n",
    "    plt.plot(gamma_range,score) \n",
    "    return gamma_range[score.index(max(score))]\n",
    "\n",
    "#grid search\n",
    "def test_svm_function2(X_train,Y_train):\n",
    "    gamma_range=np.logspace(-10,1,20)\n",
    "    coef0_range=np.linspace(0,5,10)\n",
    "\n",
    "    param_grid=dict(gamma=gamma_range,coef0=coef0_range)\n",
    "\n",
    "    cv=StratifiedShuffleSplit(n_splits=10,test_size=0.3,random_state=420)\n",
    "    grid=GridSearchCV(SVC(kernel=\"rbf\"),param_grid=param_grid,cv=cv) \n",
    "    grid.fit(X_train,Y_train)\n",
    "    print(\"The best parameters are %s with a score of %0.5f\"%(grid.best_params_,grid.best_score_))\n",
    "\n",
    "def Kfold():\n",
    "    table=pd.DataFrame(columns=['precision','recall','f1','accuracy'])\n",
    "    kf = KFold(n_splits=10)\n",
    "    print (kf)\n",
    "    random.shuffle(dataset_full) \n",
    "    kf.get_n_splits(dataset_full)\n",
    "    index=0\n",
    "    for train_index, test_index in kf.split(dataset_full):\n",
    "        train_set_fold=[]\n",
    "        test_set_fold=[]\n",
    "        accuracy_total=0.0\n",
    "        index+=1\n",
    "        for i,instance in enumerate(dataset_full):\n",
    "            if i in train_index:\n",
    "                train_set_fold.append(instance)\n",
    "            else:\n",
    "                test_set_fold.append(instance)\n",
    "                \n",
    "        vocabulary_fold=get_vocabulary(train_set_fold, 1000)\n",
    "        svm_clf_fold=train_svm_classifier(train_set_fold, vocabulary_fold)\n",
    "        X_test_fold=[]\n",
    "        Y_test_fold=[]\n",
    "        for instance in test_set_fold:\n",
    "            vector_instance=get_vector_text(vocabulary_fold,instance[0])\n",
    "            X_test_fold.append(vector_instance)\n",
    "            Y_test_fold.append(instance[1])\n",
    "        Y_test_fold_gold=np.asarray(Y_test_fold)\n",
    "        X_test_fold=np.asarray(X_test_fold)\n",
    "        Y_test_predictions_fold=svm_clf_fold.predict(X_test_fold)\n",
    "        print (\"Fold completed.\")\n",
    "        ### compute different value ###\n",
    "        print(\"Test data score:\"+str(svm_clf_fold.score(X_test_fold,Y_test_fold_gold)))\n",
    "        accuracy_fold=accuracy_score(Y_test_fold_gold, Y_test_predictions_fold)\n",
    "        accuracy_total+=accuracy_fold             \n",
    "        precision_fold=precision_score(Y_test_fold_gold, Y_test_predictions_fold, average='macro')\n",
    "        recall_fold=recall_score(Y_test_fold_gold, Y_test_predictions_fold, average='macro')\n",
    "        f1_fold=f1_score(Y_test_fold_gold, Y_test_predictions_fold, average='macro')\n",
    "        ### draw the graph ###\n",
    "        table=table.append(pd.DataFrame({'precision':precision_fold,'recall':recall_fold,'f1':f1_fold,'accuracy':accuracy_fold},index=[index]))\n",
    "    average_accuracy=accuracy_total/10\n",
    "    print (\"\\nAverage Accuracy: \"+str(round(accuracy_fold,3)))\n",
    "    print (table)\n",
    "#train_svm_classifier(dataset_full,get_vocabulary(dataset_full, 100))\n",
    "Kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
